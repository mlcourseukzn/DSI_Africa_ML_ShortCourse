---
title: "Final Project"
output: html_document
---

You and your team of data scientists were hired by a company to gain insights on the dataset in your chosen prompt. 

1. Perform any necessary data pre-processing and cleaning, and document your steps. Depending on the prompt you selected, this may involve transforming variables, creating new variables, and merging data frames. In particular, you may need to make some decisions on how to handle missing data, such as removing rows or columns with a significant amount of missing observations, creating an "unknown" category, or replacing/imputing the missing values. You do not need to develop a rigorous process or cite references, but please briefly justify your choices. 

```{r}

library(tidyverse)
library(lubridate)

allegations <- read_csv("allegations_202007271729.csv")

allegations_clean <- allegations %>%
  mutate(date_received = mdy(paste("01", month_received, year_received))) %>%
  mutate(date_closed = mdy(paste("01", month_closed, year_closed))) %>%
  mutate(time_to_disposition = interval(date_received, date_closed) %/% months(1)) %>%
  mutate(board_disposition = case_when(str_detect(board_disposition, "Substantiated") ~ "Substantiated", TRUE ~ board_disposition)) %>%
  filter(!(board_disposition %in% c("Exonerated")))

```

2. Make and interpret 4-10 visualizations to help you understand the relationships between the variables in your dataset. We highly encourage you to explore the data on your own, but when preparing your response to this question, please be parsimonious in your plots and select visualizations that help you tell a story about the data. If you need to make additional plots to support your responses to the other questions (e.g. to motivate data cleaning or modeling choices), that's fine. 

```{r}

## Some plots

library(ggplot2)

#Predictors of interest
  #time_to_disposition
  #fado_type (complaint category)
  #complaint_age_incident (complainant age)
  #complaint_gender (complainant gender)
  #complaint_ethnicity (complainant ethnicity)
  #mos_age_incident (officer age)
  #mos_gender (officer gender)
  #mos_ethnicity (officer ehtnicity)
  #precinct

allegations_clean %>%
  ggplot(aes(x = board_disposition, y = time_to_disposition)) +
   geom_boxplot() + 
  facet_grid(cols = vars(mos_ethnicity)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(title="[Title Here]", y="Time to Disposition", x="Disposition")

allegations_clean %>%
  ggplot(aes(x = fado_type)) +
  geom_bar() + 
  facet_grid(cols = vars(board_disposition)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(title="[Title Here]", y="Frequency", x="Complaint Category")
  
```

3. Build any 2 machine learning models that use your choice of covariates to predict the given outcome variable. Explain why you chose those covariates and interpret the model performances. If you are including categorical variables as covariates in a `glmnet` model (lasso or ridge regression), please remember that you will need to convert your covariate data frame into a *model matrix*, e.g. by calling the `model.matrix` function:

```{r}

#Potential predictors of interest
  #time_to_disposition
  #fado_type (complaint category)
  #complainant_age_incident (complainant age)
  #complainant_gender (complainant gender)
  #complainant_ethnicity (complainant ethnicity)
  #mos_age_incident (officer age)
  #mos_gender (officer gender)
  #mos_ethnicity (officer ethnicity)
  #precinct

#Create dataset with no missing outcome/predictors
NAs <- is.na(allegations_clean$board_disposition) | is.na(allegations_clean$time_to_disposition) | is.na(allegations_clean$fado_type) | is.na(allegations_clean$complainant_age_incident) | is.na(allegations_clean$complainant_gender) | is.na(allegations_clean$complainant_ethnicity) | is.na(allegations_clean$mos_age_incident) | is.na(allegations_clean$mos_gender) | is.na(allegations_clean$mos_ethnicity) | is.na(allegations_clean$precinct) 
allegations_clean.nomiss <- allegations_clean[!NAs,]

#Split into training and testing sets

#Decision tree
library(caret)
library(rpart)
library(rpart.plot)

set.seed(1234)

trainIndex <- createDataPartition(allegations_clean.nomiss$board_disposition, 
                                  p = .80, 
                                  list = FALSE, 
                                  times = 1)

  train <- allegations_clean.nomiss[trainIndex, ]
  test <- allegations_clean.nomiss[-trainIndex, ]
  
dim(train)
dim(test)

#Generate decision tree 
dtree <- rpart(formula = board_disposition ~ time_to_disposition + fado_type + complainant_age_incident + complainant_gender + complainant_ethnicity + mos_age_incident + mos_gender + mos_ethnicity + precinct, data = train, method = "class",control = rpart.control(cp=0.0025))

summary(dtree)
rpart.plot(dtree)

```




```{R}

#Ridge regression - may not use

#Convert covariate data frame into model matrix
covariate.matrix <- allegations_clean.nomiss %>% select(time_to_disposition,fado_type, complainant_age_incident, complainant_gender, complainant_ethnicity, mos_age_incident, mos_gender, mos_ethnicity, precinct)

x.matrix = model.matrix(~.-1, covariate.matrix)

#Perform ridge regression with k-fold cross-validation 
library(glmnet)

set.seed(1234)

fitRidge.cv <- cv.glmnet(x = x.matrix, 
                   y = allegations_clean.nomiss$board_disposition, 
                   family = "binomial", 
                   alpha = 0, )

#Obtain final estimate for which the lambda value minimizes cross-validated error
fitRidge.cv$lambda.min

#Generate coefficient profile plot (“path plot”) which shows variation of the model parameters over the possible selections of log lambda
plot(fitRidge.cv$glmnet.fit, xvar="lambda")

#Print coefficients from model where lambda value minimizes cross-validated error
coef(fitRidge.cv,s="lambda.min") 

```


4. The company stakeholders want to know what decision they should make on their stated goal/question. Based on your analysis, make recommendations for a non-technical audience. 

5. Any additional information that might be useful to collect/have? Other open-ended/non-coding question(s)? 


### NYPD complaints

The file `allegations_202007271729.csv` contains records about closed cases for every police officer on the NYPD force as of late June 2020 who had at least one substantiated allegation against them, spanning from September 1985 to January 2020. Information on the variables in this dataset can be found in `CCRB Data Layout Table.xlsx`. This data was downloaded from 
[Kaggle](https://www.kaggle.com/datasets/mrmorj/civilian-complaints-against-nyc-police-officers) and originally reported on by ProPublica. Your goal is to recommend a model to predict the disposition ruled by the Civilian Complaint Review Board (CCRB) and identify key variables that appear to be associated with the board's ruling. 

Please restrict your analysis to observations that were either "Substantiated" or "Exonerated", excluding observations that were "Unsubstantiated". This means that your models should predict whether the CCRB determined that the officer violated NYPD rules (yes = Substantiated, no = Exonerated), excluding cases where the CCRB could not conclude if the conduct occurred (Unsubstantiated). If you choose to incorporate information on officer rank and command, you will most likely want to collapse or otherwise simplify the categories for these variables (see the Rank Abbrevs and Command Abbrevs tabs in `CCRB Data Layout Table.xlsx`). If you do so, please briefly justify your reasoning. 

